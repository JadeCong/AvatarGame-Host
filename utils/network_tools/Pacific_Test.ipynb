{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module name</th>\n",
       "      <th>input shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>parameters</th>\n",
       "      <th>infer memory(MB)</th>\n",
       "      <th>MAdd</th>\n",
       "      <th>Flops</th>\n",
       "      <th>MemRead(B)</th>\n",
       "      <th>MemWrite(B)</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>features.0</td>\n",
       "      <td>(1, 3, 224, 224)</td>\n",
       "      <td>(1, 64, 55, 55)</td>\n",
       "      <td>23,296</td>\n",
       "      <td>0.738525390625</td>\n",
       "      <td>140,553,600</td>\n",
       "      <td>70,470,400</td>\n",
       "      <td>695,296</td>\n",
       "      <td>774,400</td>\n",
       "      <td>0.015694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>features.1</td>\n",
       "      <td>(1, 64, 55, 55)</td>\n",
       "      <td>(1, 64, 55, 55)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738525390625</td>\n",
       "      <td>193,600</td>\n",
       "      <td>193,600</td>\n",
       "      <td>774,400</td>\n",
       "      <td>774,400</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>features.2</td>\n",
       "      <td>(1, 64, 55, 55)</td>\n",
       "      <td>(1, 64, 27, 27)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177978515625</td>\n",
       "      <td>373,248</td>\n",
       "      <td>419,904</td>\n",
       "      <td>774,400</td>\n",
       "      <td>186,624</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>features.3</td>\n",
       "      <td>(1, 64, 27, 27)</td>\n",
       "      <td>(1, 192, 27, 27)</td>\n",
       "      <td>307,392</td>\n",
       "      <td>0.533935546875</td>\n",
       "      <td>447,897,600</td>\n",
       "      <td>224,088,768</td>\n",
       "      <td>1,416,192</td>\n",
       "      <td>559,872</td>\n",
       "      <td>0.000647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>features.4</td>\n",
       "      <td>(1, 192, 27, 27)</td>\n",
       "      <td>(1, 192, 27, 27)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533935546875</td>\n",
       "      <td>139,968</td>\n",
       "      <td>139,968</td>\n",
       "      <td>559,872</td>\n",
       "      <td>559,872</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>features.5</td>\n",
       "      <td>(1, 192, 27, 27)</td>\n",
       "      <td>(1, 192, 13, 13)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123779296875</td>\n",
       "      <td>259,584</td>\n",
       "      <td>292,032</td>\n",
       "      <td>559,872</td>\n",
       "      <td>129,792</td>\n",
       "      <td>0.000594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>features.6</td>\n",
       "      <td>(1, 192, 13, 13)</td>\n",
       "      <td>(1, 384, 13, 13)</td>\n",
       "      <td>663,936</td>\n",
       "      <td>0.24755859375</td>\n",
       "      <td>224,280,576</td>\n",
       "      <td>112,205,184</td>\n",
       "      <td>2,785,536</td>\n",
       "      <td>259,584</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>features.7</td>\n",
       "      <td>(1, 384, 13, 13)</td>\n",
       "      <td>(1, 384, 13, 13)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24755859375</td>\n",
       "      <td>64,896</td>\n",
       "      <td>64,896</td>\n",
       "      <td>259,584</td>\n",
       "      <td>259,584</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>features.8</td>\n",
       "      <td>(1, 384, 13, 13)</td>\n",
       "      <td>(1, 256, 13, 13)</td>\n",
       "      <td>884,992</td>\n",
       "      <td>0.1650390625</td>\n",
       "      <td>299,040,768</td>\n",
       "      <td>149,563,648</td>\n",
       "      <td>3,799,552</td>\n",
       "      <td>173,056</td>\n",
       "      <td>0.000610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>features.9</td>\n",
       "      <td>(1, 256, 13, 13)</td>\n",
       "      <td>(1, 256, 13, 13)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1650390625</td>\n",
       "      <td>43,264</td>\n",
       "      <td>43,264</td>\n",
       "      <td>173,056</td>\n",
       "      <td>173,056</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>features.10</td>\n",
       "      <td>(1, 256, 13, 13)</td>\n",
       "      <td>(1, 256, 13, 13)</td>\n",
       "      <td>590,080</td>\n",
       "      <td>0.1650390625</td>\n",
       "      <td>199,360,512</td>\n",
       "      <td>99,723,520</td>\n",
       "      <td>2,533,376</td>\n",
       "      <td>173,056</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>features.11</td>\n",
       "      <td>(1, 256, 13, 13)</td>\n",
       "      <td>(1, 256, 13, 13)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1650390625</td>\n",
       "      <td>43,264</td>\n",
       "      <td>43,264</td>\n",
       "      <td>173,056</td>\n",
       "      <td>173,056</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>features.12</td>\n",
       "      <td>(1, 256, 13, 13)</td>\n",
       "      <td>(1, 256, 6, 6)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03515625</td>\n",
       "      <td>73,728</td>\n",
       "      <td>82,944</td>\n",
       "      <td>173,056</td>\n",
       "      <td>36,864</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>avgpool</td>\n",
       "      <td>(1, 256, 6, 6)</td>\n",
       "      <td>(1, 256, 6, 6)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03515625</td>\n",
       "      <td>0</td>\n",
       "      <td>36,864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>classifier.0</td>\n",
       "      <td>(1, 9216)</td>\n",
       "      <td>(1, 9216)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03515625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>classifier.1</td>\n",
       "      <td>(1, 9216)</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>37,752,832</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>75,493,376</td>\n",
       "      <td>37,748,736</td>\n",
       "      <td>151,048,192</td>\n",
       "      <td>16,384</td>\n",
       "      <td>0.006814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>classifier.2</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4,096</td>\n",
       "      <td>4,096</td>\n",
       "      <td>16,384</td>\n",
       "      <td>16,384</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>classifier.3</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>classifier.4</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>16,781,312</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>33,550,336</td>\n",
       "      <td>16,777,216</td>\n",
       "      <td>67,141,632</td>\n",
       "      <td>16,384</td>\n",
       "      <td>0.002338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>classifier.5</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4,096</td>\n",
       "      <td>4,096</td>\n",
       "      <td>16,384</td>\n",
       "      <td>16,384</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>classifier.6</td>\n",
       "      <td>(1, 4096)</td>\n",
       "      <td>(1, 1000)</td>\n",
       "      <td>4,097,000</td>\n",
       "      <td>0.003814697265625</td>\n",
       "      <td>8,191,000</td>\n",
       "      <td>4,096,000</td>\n",
       "      <td>16,404,384</td>\n",
       "      <td>4,000</td>\n",
       "      <td>0.000765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Model</td>\n",
       "      <td>[1, 3, 224, 224]</td>\n",
       "      <td>(1, 1000)</td>\n",
       "      <td>61,100,840</td>\n",
       "      <td>4.189361572265625</td>\n",
       "      <td>1,429,567,512</td>\n",
       "      <td>715,998,400</td>\n",
       "      <td>249,304,224</td>\n",
       "      <td>4,302,752</td>\n",
       "      <td>0.031155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     module name       input shape      output_shape  parameters   infer memory(MB)           MAdd        Flops   MemRead(B) MemWrite(B)  duration\n",
       "0     features.0  (1, 3, 224, 224)   (1, 64, 55, 55)      23,296     0.738525390625    140,553,600   70,470,400      695,296     774,400  0.015694\n",
       "1     features.1   (1, 64, 55, 55)   (1, 64, 55, 55)           0     0.738525390625        193,600      193,600      774,400     774,400  0.000440\n",
       "2     features.2   (1, 64, 55, 55)   (1, 64, 27, 27)           0     0.177978515625        373,248      419,904      774,400     186,624  0.001300\n",
       "3     features.3   (1, 64, 27, 27)  (1, 192, 27, 27)     307,392     0.533935546875    447,897,600  224,088,768    1,416,192     559,872  0.000647\n",
       "4     features.4  (1, 192, 27, 27)  (1, 192, 27, 27)           0     0.533935546875        139,968      139,968      559,872     559,872  0.000021\n",
       "5     features.5  (1, 192, 27, 27)  (1, 192, 13, 13)           0     0.123779296875        259,584      292,032      559,872     129,792  0.000594\n",
       "6     features.6  (1, 192, 13, 13)  (1, 384, 13, 13)     663,936      0.24755859375    224,280,576  112,205,184    2,785,536     259,584  0.000497\n",
       "7     features.7  (1, 384, 13, 13)  (1, 384, 13, 13)           0      0.24755859375         64,896       64,896      259,584     259,584  0.000022\n",
       "8     features.8  (1, 384, 13, 13)  (1, 256, 13, 13)     884,992       0.1650390625    299,040,768  149,563,648    3,799,552     173,056  0.000610\n",
       "9     features.9  (1, 256, 13, 13)  (1, 256, 13, 13)           0       0.1650390625         43,264       43,264      173,056     173,056  0.000019\n",
       "10   features.10  (1, 256, 13, 13)  (1, 256, 13, 13)     590,080       0.1650390625    199,360,512   99,723,520    2,533,376     173,056  0.000388\n",
       "11   features.11  (1, 256, 13, 13)  (1, 256, 13, 13)           0       0.1650390625         43,264       43,264      173,056     173,056  0.000019\n",
       "12   features.12  (1, 256, 13, 13)    (1, 256, 6, 6)           0         0.03515625         73,728       82,944      173,056      36,864  0.000207\n",
       "13       avgpool    (1, 256, 6, 6)    (1, 256, 6, 6)           0         0.03515625              0       36,864            0           0  0.000373\n",
       "14  classifier.0         (1, 9216)         (1, 9216)           0         0.03515625              0            0            0           0  0.000360\n",
       "15  classifier.1         (1, 9216)         (1, 4096)  37,752,832           0.015625     75,493,376   37,748,736  151,048,192      16,384  0.006814\n",
       "16  classifier.2         (1, 4096)         (1, 4096)           0           0.015625          4,096        4,096       16,384      16,384  0.000023\n",
       "17  classifier.3         (1, 4096)         (1, 4096)           0           0.015625              0            0            0           0  0.000012\n",
       "18  classifier.4         (1, 4096)         (1, 4096)  16,781,312           0.015625     33,550,336   16,777,216   67,141,632      16,384  0.002338\n",
       "19  classifier.5         (1, 4096)         (1, 4096)           0           0.015625          4,096        4,096       16,384      16,384  0.000012\n",
       "20  classifier.6         (1, 4096)         (1, 1000)   4,097,000  0.003814697265625      8,191,000    4,096,000   16,404,384       4,000  0.000765\n",
       "21         Model  [1, 3, 224, 224]         (1, 1000)  61,100,840  4.189361572265625  1,429,567,512  715,998,400  249,304,224   4,302,752  0.031155"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models\n",
    "import tensorwatch as tw # pip install tensorwatch\n",
    "\n",
    "alexnet_model = torchvision.models.alexnet()\n",
    "tw.model_stats(alexnet_model, [1, 3, 224, 224])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.onnx' has no attribute 'set_training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c4e112416b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0malexnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malexnet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/humanpose3d/lib/python3.6/site-packages/tensorwatch/__init__.py\u001b[0m in \u001b[0;36mdraw_model\u001b[0;34m(model, input_shape, orientation, png_filename)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdraw_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpng_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#orientation = 'LR' for landscpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddenlayer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_draw_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch_draw_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/humanpose3d/lib/python3.6/site-packages/tensorwatch/model_graph/hiddenlayer/pytorch_draw_model.py\u001b[0m in \u001b[0;36mdraw_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_img_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDotWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/humanpose3d/lib/python3.6/site-packages/tensorwatch/model_graph/hiddenlayer/pytorch_draw_model.py\u001b[0m in \u001b[0;36mdraw_img_classifier\u001b[0;34m(model, dataset, display_param_nodes, rankdir, styles, input_shape)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mnon_para_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_non_parallel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_para_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msgraph2dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_param_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/humanpose3d/lib/python3.6/site-packages/tensorwatch/model_graph/hiddenlayer/summary_graph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, dummy_input, apply_scope_name_workarounds)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mmodel_clone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_module_names_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_distiller_modulelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_clone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_clone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_clone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.onnx' has no attribute 'set_training'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models\n",
    "import tensorwatch as tw # pip install tensorwatch\n",
    "\n",
    "alexnet_model = torchvision.models.alexnet()\n",
    "tw.draw_model(alexnet_model, [1, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.resnet.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.resnet.ResNet'>. Treat it as zero Macs and zero Params.\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "from thop import profile\n",
    "\n",
    "model = resnet50()\n",
    "input = torch.randn(1, 3, 224, 224)\n",
    "flops, params = profile(model, inputs=(input, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}